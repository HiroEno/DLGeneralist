// glossaryファイル DLGeneral
`use strict`
const glossary = [
{target:`ーーーーー`, content:`1. 人工知能とは（定義・基本概念）`},
{target:`AI効果`, content:`実現すると当たり前になりAIと見なされなくなる現象`},
{target:`エージェント`, content:`環境を観測し方策に従い行動する自律的主体`},
{target:`人工知能`, content:`人の知的行為を計算で模倣・拡張する技術と学問領域`},
{target:`機械学習`, content:`データから規則性を学び予測・判断を自動化する手法群`},
{target:`ディープラーニング`, content:`多層NNで表現学習を行う機械学習の一分野`},
{target:`ーーーーー`, content:`2. 人工知能分野で議論される問題`},
{target:`シンギュラリティ`, content:`技術的特異点。AIが人間知能を超えるとされる転換点`},
{target:`シンボルグラウンディング問題`, content:`記号の意味を知覚・経験に結び付ける困難`},
{target:`身体性`, content:`知能が身体・環境との相互作用に依存するという観点`},
{target:`ダートマス会議`, content:`1956年のAI研究の出発点とされる会議`},
{target:`トイ・プロブレム`, content:`研究用の簡単化された問題設定。実環境との乖離が課題`},
{target:`知識獲得のボトルネック`, content:`ルールや知識を人手で整備するコスト・困難`},
{target:`チューリングテスト`, content:`会話で人間と区別不能なら知的と見なす試験`},
{target:`中国語の部屋`, content:`記号操作だけでは理解は生じないとする思考実験`},
{target:`強いAIと弱いAI`, content:`心を持つAI（強い）と特定タスク特化（弱い）の区別`},
{target:`統計的機械翻訳`, content:`並列コーパス統計に基づく翻訳手法（NMT前の主流）`},
{target:`フレーム問題`, content:`何が重要かを選び更新する知識表現上の難題`},
{target:`ルールベース機械翻訳`, content:`手作り辞書・規則で変換する伝統的翻訳方式`},
{target:`ローブナーコンテスト`, content:`年次対話テスト。人間らしさを競うTuring Test系競技`},
{target:`ーーーーー`, content:`3. 探索・推論`},
{target:`αβ法`, content:`ミニマックスの不要分枝を刈る枝刈り最適化手法`},
{target:`Mini-Max法`, content:`ゲームで最悪ケースを最小化する探索戦略`},
{target:`SHRDLU`, content:`自然言語でブロック操作を行う初期対話システム`},
{target:`STRIPS`, content:`プランニングの状態・演算子表現と探索枠組み`},
{target:`探索木`, content:`状態遷移を木構造で表し探索する表現`},
{target:`ハノイの塔`, content:`再帰・状態空間探索の教材となる古典課題`},
{target:`幅優先探索`, content:`同深さを先に網羅する完全探索。最短路発見向き`},
{target:`深さ優先探索`, content:`深く潜る探索。メモリ少。閉路や最適性に注意`},
{target:`ブルートフォース`, content:`可能性を総当たりで列挙する単純探索`},
{target:`モンテカルロ法`, content:`乱数サンプリングで期待値や戦略を評価する手法`},
{target:`ーーーーー`, content:`4. 知識表現とエキスパートシステム`},
{target:`Cycプロジェクト`, content:`常識知識を大規模形式知識として構築する試み`},
{target:`DENDRAL`, content:`化学構造推定の初期エキスパートシステム`},
{target:`is-a関係`, content:`階層的な継承関係（犬は動物）`},
{target:`has-a関係`, content:`所有・属性関係（車はエンジンを持つ）`},
{target:`part-of関係`, content:`部分−全体関係（車輪は車の一部）`},
{target:`Question-Answering`, content:`問いに対し知識から直接回答を生成する技術`},
{target:`意味ネットワーク`, content:`概念と関係をグラフで表す知識表現`},
{target:`ELIZA`, content:`反射的応答規則で擬似対話を行う初期プログラム`},
{target:`インタビューシステム`, content:`質問に基づき知識ベースで診断・助言する枠組み`},
{target:`ウェブマイニング`, content:`Webデータからパターンを抽出する手法群`},
{target:`オントロジー`, content:`概念・関係の体系的定義。相互運用の基礎。`},
{target:`セマンティックWeb`, content:`Webに機械可読な意味情報を付与する構想`},
{target:`データマイニング`, content:`大量データから有用知識を抽出する分析`},
{target:`東ロボくん`, content:`大学入試突破を目標にしたAI研究プロジェクト`},
{target:`MYCIN`, content:`ルールベースの感染症診断エキスパートシステム`},
{target:`ワトソン`, content:`Jeopardy!で人間王者に勝利したQAシステム`},
{target:`ーーーーー`, content:`5. 機械学習（動向）`},
{target:`次元の呪い`, content:`特徴次元増加で疎密・距離直観が崩れる問題`},
{target:`スパムフィルタ`, content:`学習により迷惑メールを自動判別する応用`},
{target:`ビッグデータ`, content:`多量・多様・高速なデータ群の活用概念`},
{target:`レコメンデーションエンジン`, content:`行動・類似性に基づきアイテムを推薦する仕組み`},
{target:`統計的自然言語処理`, content:`確率モデルで言語データを扱うNLP手法群`},
{target:`ーーーーー`, content:`6. ディープラーニング（歴史・動向）`},
{target:`ImageNet`, content:`大規模画像データ。2012年以降DL進展を牽引`},
{target:`ILSVRC`, content:`ImageNetの年次画像認識コンペティション`},
{target:`LeNet`, content:`手書き数字認識で成功した初期CNN`},
{target:`AlphaGo`, content:`モンテカルロ木探索とDLで囲碁に勝利したAI`},
{target:`人間の神経回路`, content:`ニューロン・シナプスを抽象化しNN設計へ示唆`},
{target:`ネオコグニトロン`, content:`CNNの原型。局所受容野と階層構造を採用`},
{target:`生成AI`, content:`学習分布から新規データを生成するモデル群`},
{target:`ーーーーー`, content:`7. 教師あり学習（代表手法）`},
{target:`アンサンブル学習`, content:`複数モデルを組み合わせて予測精度を高める手法`},
{target:`カーネル`, content:`データを高次元空間に写像する関数`},
{target:`カーネルトリック`, content:`高次元計算を効率的に行う手法`},
{target:`回帰問題`, content:`連続値を予測する教師あり学習のタスク`},
{target:`決定木`, content:`条件分岐でデータを分類する木構造モデル`},
{target:`勾配ブースティング`, content:`弱学習器を逐次学習させて精度向上する手法`},
{target:`SVM`, content:`マージン最大化で分類境界を学習する教師ありモデル`},
{target:`線形回帰`, content:`入力の線形結合で目的変数を近似する`},
{target:`ARモデル`, content:`過去値から現在を回帰する時系列モデル`},
{target:`単回帰分析`, content:`1説明変数で関係を推定する回帰`},
{target:`重回帰分析`, content:`複数説明変数で関係を推定する回帰`},
{target:`多クラス分類`, content:`3クラス以上を識別する分類設定`},
{target:`バギング`, content:`データ再標本化で多数決統合する手法`},
{target:`ブースティング`, content:`弱いモデルを組み合わせ精度を向上させる手法`},
{target:`ブートストラップサンプリング`, content:`データを復元抽出して学習する手法`},
{target:`分類問題`, content:`カテゴリラベルを予測する機械学習の課題`},
{target:`VARモデル`, content:`複数時系列の相互依存を表すモデル`},
{target:`マージン最大化`, content:`分類境界とデータの距離を最大化する手法`},
{target:`ランダムフォレスト`, content:`複数決定木で予測し過学習を抑制する手法`},
{target:`ロジスティック回帰`, content:`確率を出力する二値分類モデル`},
{target:`ーーーーー`, content:`8. 教師なし学習・推薦`},
{target:`k-means法`, content:`ユークリッド距離でクラスタ中心を最適化する非階層法`},
{target:`t-SNE`, content:`高次元データを低次元に可視化する手法`},
{target:`ウォード法`, content:`クラスタ内分散を最小化する階層型手法`},
{target:`協調フィルタリング`, content:`類似ユーザーやアイテムで推薦する手法`},
{target:`クラスタリング`, content:`類似性に基づきデータをグループ化する手法`},
{target:`コールドスタート問題`, content:`新規ユーザーやアイテム推薦が難しい問題`},
{target:`コンテンツベース`, content:`アイテム特徴で推薦する手法`},
{target:`次元削減`, content:`データの特徴数を減らし分析を容易にする手法`},
{target:`PCA`, content:`データの分散を最大化する線形次元削減法`},
{target:`LDA`, content:`クラス間の分離を最大化する教師あり次元削減法`},
{target:`MDS`, content:`距離を保ちながらデータを低次元に表現する手法`},
{target:`デンドログラム`, content:`階層クラスタリング結果を木構造で可視化`},
{target:`SVD`, content:`行列を分解し特徴抽出や圧縮に利用する手法`},
{target:`トピックモデル`, content:`文書集合から潜在トピックを抽出する手法`},
{target:`ーーーーー`, content:`9. 強化学習（基礎）`},
{target:`Actor-Critic`, content:`強化学習で行動選択と価値評価を組み合わせる手法`},
{target:`ε-greedy方策`, content:`探索と活用をランダムに切替える行動戦略`},
{target:`REINFORCE`, content:`確率方策の勾配を使った強化学習手法`},
{target:`Q学習`, content:`状態-行動価値を学習するオフポリシー手法`},
{target:`UCB方策`, content:`上限信頼区間で行動選択する探索戦略`},
{target:`行動価値関数`, content:`状態と行動の将来報酬期待値を表す関数`},
{target:`状態価値関数`, content:`状態の将来報酬期待値を表す関数`},
{target:`バンディット`, content:`1回選択で報酬を得る意思決定問題`},
{target:`方策勾配法`, content:`方策パラメータの勾配で最適化する手法`},
{target:`マルコフ決定過程`, content:`状態・行動・報酬で表す意思決定モデル`},
{target:`割引率`, content:`将来報酬の重要度を減らす係数`},
{target:`SARSA`, content:`行動選択も学習に組み込むオンポリシー法`},
{target:`ーーーーー`, content:`10. モデルの選択・評価`},
{target:`k-分割交差検証`, content:`データをk分割し学習・評価を繰り返す手法`},
{target:`MSE`, content:`平均二乗誤差で予測精度を評価する指標`},
{target:`RMSE`, content:`二乗誤差平方根で予測誤差を評価する指標`},
{target:`MAE`, content:`平均絶対誤差で予測誤差を評価する指標`},
{target:`ROC曲線・AUC`, content:`分類性能を偽陽性率と真陽性率で評価`},
{target:`AIC`, content:`モデルの当てはまりと複雑性を評価する指標`},
{target:`オッカムの剃刀`, content:`不要な仮定を削り単純モデルを優先する原理`},
{target:`過学習`, content:`訓練データに過度に適合し汎化性能低下`},
{target:`交差検証`, content:`データ分割でモデル性能を安定評価する手法`},
{target:`真陽性（TP: True Positive）`, content:`実際に陽性のデータを正しく陽性と判定した数`},
{target:`偽陽性（FP: False Positive）`, content:`実際は陰性なのに誤って陽性と判定した数`},
{target:`真陰性（TN: True Negative）`, content:`実際に陰性のデータを正しく陰性と判定した数`},
{target:`偽陰性（FN: False Negative）`, content:`実際は陽性なのに誤って陰性と判定した数`},
{target:`混同行列`, content:`分類結果の正解・誤分類を表形式で示す表`},
{target:`正解率（Accuracy）`, content:`全データに対して正しく分類された割合。(TP+TN)/全データ`},
{target:`適合率（Precision）`, content:`予測陽性のうち正しく陽性と判定された割合。偽陽性が少ないほど高い。TP/(TP+FP)`},
{target:`再現率（Recall / Sensitivity）`, content:`実際の陽性のうち正しく陽性と判定された割合。偽陰性が少ないほど高い。(TP/(TP+FN))`},
{target:`F値（F1-score）`, content:`適合率と再現率の調和平均。バランス良く評価する指標。2*Precision*Recall/(Precision+Recall)`},
{target:`汎化性能`, content:`未知データに対するモデルの適応能力`},
{target:`BIC`, content:`AIC同様モデル評価だが複雑度に重罰を課す指標`},
{target:`ホールドアウト検証`, content:`データを学習用と評価用に分ける手法`},
{target:`ーーーーー`, content:`11. ニューラルネットワークとディープラーニング`},
{target:`CPU`, content:`汎用計算装置。制御処理に適する`},
{target:`GPU`, content:`行列演算並列計算に優れDL学習を高速化`},
{target:`TPU`, content:`Google開発。DL専用演算器で効率高`},
{target:`隠れ層・入力層・出力層`, content:`NNの基本構造。入力変換し出力へ導く`},
{target:`多層パーセプトロン`, content:`複数隠れ層を持つNN。非線形関数近似が可能`},
{target:`単純パーセプトロン`, content:`線形分離問題のみ解ける最小NNモデル`},
{target:`ーーーーー`, content:`12. 活性化関数`},
{target:`ReLU関数`, content:`負値を0に、正値をそのまま出力する活性化`},
{target:`Leaky ReLU`, content:`負値も微小勾配を持ち消失を防ぐ`},
{target:`tanh関数`, content:`-1〜1に正規化。中心対称`},
{target:`シグモイド関数`, content:`0〜1に正規化。勾配消失に弱い`},
{target:`ソフトマックス関数`, content:`多クラス分類確率分布に変換`},
{target:`勾配消失問題`, content:`深層で勾配が極小化し学習困難化`},
{target:`ーーーーー`, content:`13. 誤差関数`},
{target:`MSE`, content:`残差二乗の平均。回帰で広く用いる`},
{target:`Contrastive Loss`, content:`類似・非類似ペアの距離を学習する損失関数`},
{target:`Triplet Loss`, content:`アンカー・正例・負例で距離を学習する損失`},
{target:`KL情報量`, content:`2分布の差異を測る情報理論指標`},
{target:`交差エントロピー`, content:`正解分布との誤差を測る損失関数`},
{target:`ーーーーー`, content:`14. 正則化`},
{target:`L0正則化`, content:`非ゼロパラメータ数を減らす正則化手法`},
{target:`L1正則化`, content:`パラメータの絶対値を罰する疎正則化手法`},
{target:`L2正則化`, content:`パラメータの二乗を罰する滑らか正則化手法`},
{target:`ドロップアウト`, content:`学習中にランダムにノードを無効化する手法`},
{target:`ラッソ回帰`, content:`L1正則化を用いた回帰モデル`},
{target:`リッジ回帰`, content:`L2正則化を用いた回帰モデル`},
{target:`ーーーーー`, content:`15. 誤差逆伝播法`},
{target:`誤差逆伝播法`, content:`ニューラルネット重みを効率的に更新する手法`},
{target:`勾配消失問題`, content:`深いネットワークで勾配が小さく学習困難になる現象`},
{target:`勾配爆発問題`, content:`勾配が大きくなり学習が不安定になる現象`},
{target:`信用割当問題`, content:`リソース配分で信頼度に応じて割当を行う問題`},
{target:`連鎖律`, content:`微分の合成関数の導関数計算に使う法則`},
{target:`ーーーーー`, content:`16. 最適化手法`},
{target:`AdaBound`, content:`学習率に上下の境界を設け、AdamからSGDへ滑らかに遷移する最適化法。`},
{target:`AdaDelta`, content:`過去勾配の二乗平均で学習率を自動調整する改良型最適化手法`},
{target:`AdaGrad`, content:`頻出パラメータの学習率を下げ、稀な特徴に高学習率を与える手法。`},
{target:`Adam`, content:`勾配の1次・2次モーメントを使い適応的に学習率を調整する最適化法。`},
{target:`AMSBound`, content:`AMSGradに学習率の動的境界を導入し収束性を改善した変種。`},
{target:`RMSprop`, content:`勾配の二乗の指数移動平均で学習率を調整する実用的手法。`},
{target:`鞍点`, content:`勾配がゼロだが最小でもない点。学習が停滞しやすい場所`},
{target:`イテレーション`, content:`学習でパラメータを1回更新する反復処理の単位`},
{target:`エポック`, content:`データセット全体を1回使って学習する処理の一巡`},
{target:`オンライン学習`, content:`データが順次来る前提で逐次更新する学習方式`},
{target:`学習率`, content:`重み更新のステップ幅。大きすぎると不安定、小さすぎると遅い`},
{target:`確率的勾配降下法 (SGD)`, content:`ミニバッチで近似勾配を使い反復更新する基本的最適化法。`},
{target:`グリッドサーチ`, content:`候補の全組合せを総当たりで試すハイパーパラメータ探索法`},
{target:`勾配降下法`, content:`誤差を減らす方向（勾配の逆）へパラメータを更新する基礎法`},
{target:`局所最適解`, content:`近傍では最良だが、全体では最良でない解に収束した状態`},
{target:`早期終了`, content:`検証誤差が悪化したら学習を止め過学習を防ぐ手法`},
{target:`大域最適解`, content:`探索空間全体で最も誤差が小さい真の最良解`},
{target:`二重降下現象`, content:`容量増加で誤差が一度増え再び減る、二段階で改善する現象`},
{target:`ノーフリーランチの定理`, content:`全ての問題で常に最良な手法は存在しないという理論`},
{target:`ハイパーパラメータ`, content:`学習前に設定する調整値（例：学習率、バッチサイズ）`},
{target:`バッチ学習`, content:`全データで一括して勾配を計算・更新する学習方式`},
{target:`ミニバッチ学習`, content:`データを小分けにして効率よく反復学習する方式`},
{target:`モーメンタム`, content:`過去の更新を加味し振動を抑え学習を加速する仕組み`},
{target:`ランダムサーチ`, content:`ハイパーパラメータをランダムに試す探索法で効率的`},
{target:`ーーーーー`, content:`17. 全結合層`},
{target:`重み`, content:`ニューラルネットが学習するパラメータ。入力の影響度を調整し出力を決定`},
{target:`線形関数`, content:`入力の線形結合とバイアスで出力を算出する基本的演算`},
{target:`ーーーーー`, content:`18. 畳み込み層`},
{target:`Atrous Convolution`, content:`カーネル内の要素間に間隔を空け、受容野を広げ特徴抽出`},
{target:`Depthwise Separable Convolution`, content:`空間方向とチャネル方向の畳み込みを分離し計算量を削減`},
{target:`Dilated Convolution`, content:`間隔を開けた畳み込みで広範囲の特徴を効率的に取得`},
{target:`カーネル`, content:`畳み込み演算で局所特徴を抽出する小さな学習可能行列`},
{target:`ストライド`, content:`カーネルの移動幅。大きいと出力サイズは小さくなる`},
{target:`畳み込み操作`, content:`入力画像とカーネルを掛け合わせ、局所的特徴を抽出する計算`},
{target:`畳み込みニューラルネットワーク (CNN)`, content:`局所特徴抽出と階層的表現学習で画像認識に強いネットワーク`},
{target:`特徴マップ`, content:`畳み込みの出力。入力画像の重要特徴を空間的に表現`},
{target:`パディング`, content:`畳み込み時に境界情報を保持するため画像周囲にゼロを追加`},
{target:`フィルタ`, content:`特徴検出用に学習されるカーネル群で、特定パターンに反応`},
{target:`ーーーーー`, content:`19. 正規化層`},
{target:`グループ正規化`, content:`チャンネルをグループに分け平均・分散を正規化し学習安定化`},
{target:`バッチ正規化`, content:`ミニバッチ単位で出力を標準化し勾配消失・発散を抑制`},
{target:`レイヤー正規化`, content:`層内全ニューロンの出力を正規化しサンプルごとの学習安定化`},
{target:`インスタンス正規化`, content:`各サンプルの特徴マップごとに正規化しスタイル変換で有効`},
{target:`グローバルアベレージプーリング (GAP)`, content:`特徴マップの全空間平均を取って次層の全結合に入力`},
{target:`最大値プーリング`, content:`局所領域の最大値のみ残し、位置に頑健な特徴を抽出`},
{target:`平均値プーリング`, content:`局所領域の平均値で情報を滑らかに圧縮し特徴を抽出`},
{target:`不変性の獲得`, content:`平行移動・回転・スケール変化などに影響されにくい表現を学習`},
{target:`ーーーーー`, content:`21. スキップ結合`},
{target:`ResNet`, content:`残差接続により深層化しても勾配消失を抑え学習可能なCNN構造`},
{target:`ーーーーー`, content:`22. 回帰結合層`},
{target:`BPTT`, content:`RNNの時間方向の誤差を逆伝播させ学習する手法`},
{target:`GRU`, content:`LSTM簡略版。更新ゲートとリセットゲートで長期依存学習`},
{target:`LSTM`, content:`忘却ゲート・入力ゲート・出力ゲートで長期依存を保持するRNN`},
{target:`エルマンネットワーク`, content:`隠れ状態を再入力にフィードバックする基本RNN構造`},
{target:`勾配消失問題`, content:`深いネットやRNNで勾配が小さくなり学習が進まない現象`},
{target:`勾配爆発問題`, content:`勾配が大きくなり学習が不安定になる現象`},
{target:`教師強制`, content:`次の入力をモデルの予測ではなく正解で置き換え学習する手法`},
{target:`ゲート機構`, content:`RNNで情報の保持・更新を制御する仕組み`},
{target:`双方向 RNN (Bidirectional RNN)`, content:`過去と未来の文脈を同時に扱うRNN構造`},
{target:`時系列データ`, content:`時間軸に沿って並んだ連続データ`},
{target:`ジョルダンネットワーク`, content:`出力を再入力にフィードバックするRNNの一種`},
{target:`リカレントニューラルネットワーク (RNN)`, content:`時系列データを扱う再帰型ニューラルネット`},
{target:`ーーーーー`, content:`23. Attention`},
{target:`Attention`, content:`重要な部分に重みを付け情報を選択的に集約する仕組み`},
{target:`Multi-Head Attention`, content:`複数の注意機構で異なる特徴を同時に抽出するAttention`},
{target:`Self-Attention`, content:`同じ系列内の各要素間の関連性を評価するAttention`},
{target:`Seq2Seq`, content:`入力系列を別系列に変換するエンコーダ・デコーダモデル`},
{target:`Source-Target Attention`, content:`デコーダがエンコーダ出力の重要箇所に注目するAttention`},
{target:`Transformer`, content:`Attention主体で並列処理可能な系列変換モデル`},
{target:`位置エンコーディング`, content:`位置情報をベクトル化し順序情報をTransformerに伝える手法`},
{target:`キー (Key)`, content:`Attentionで参照される情報の識別子ベクトル`},
{target:`クエリ (Query)`, content:`Attentionで情報を取得するための問い合わせベクトル`},
{target:`バリュー (Value)`, content:`Attentionで取得される情報の内容ベクトル`},
{target:`ーーーーー`, content:`24. オートエンコーダ`},
{target:`VQ-VAE`, content:`離散潜在空間を用いた変分オートエンコーダ。離散表現を学習`},
{target:`info VAE`, content:`潜在変数と入力情報量を最大化する変分オートエンコーダの拡張`},
{target:`β-VAE`, content:`潜在空間の独立性を強め解釈性の高い表現を学習するVAE変種`},
{target:`次元削減`, content:`高次元データを低次元に圧縮し重要特徴を保持する手法`},
{target:`事前学習`, content:`タスク前に大量データでモデルを学習させ基盤知識を習得`},
{target:`積層オートエンコーダ`, content:`隠れ層を深く積んだ自己符号化ネットワークで特徴抽出`},
{target:`変分オートエンコーダ (VAE)`, content:`入力を確率的潜在変数に変換し生成も可能な自己符号化モデル`},
{target:`ーーーーー`, content:`25. データ拡張`},
{target:`Contrast`, content:`画像の明暗差を強める変換で特徴を際立たせるデータ拡張`},
{target:`Brightness`, content:`画像全体の明るさを調整するデータ拡張手法`},
{target:`Crop`, content:`画像の一部を切り出すことで学習多様性を増す手法`},
{target:`CutMix`, content:`複数画像を部分的に合成しラベルも混合するデータ拡張`},
{target:`Cutout`, content:`画像の一部を黒塗りし欠損状況に強いモデルを作る手法`},
{target:`Mixup`, content:`複数画像とラベルを線形混合するデータ拡張手法`},
{target:`noising`, content:`画像やテキストにノイズを加えてロバスト性を高める手法`},
{target:`paraphrasing`, content:`文を意味を保ったまま言い換えデータを増やす手法`},
{target:`RandAugument`, content:`複数のランダムデータ拡張を組み合わせ自動適用する手法`},
{target:`Random Erasing`, content:`画像のランダム領域を消去し欠損耐性を向上させる手法`},
{target:`Random Flip`, content:`画像をランダムに左右反転することで汎化性能向上`},
{target:`Rotate`, content:`画像を任意角度回転し学習データの多様性を増す手法`},
{target:`ーーーーー`, content:`26. 画像認識`},
{target:`AlexNet`, content:`2012年のCNN。ReLU・ドロップアウトで画像認識精度を大幅改善`},
{target:`DeepLab`, content:`畳み込みとAtrous Convolutionで高精度セマンティックセグメンテーション`},
{target:`DenseNet`, content:`層間を全結合で接続し勾配伝播を改善、特徴再利用効率向上`},
{target:`EfficientNet`, content:`ネット幅・深さ・解像度を同時最適化した軽量高性能CNN`},
{target:`Fast R-CNN`, content:`領域提案を入力として高速に物体検出を行うCNNモデル`},
{target:`Faster R-CNN`, content:`RPNを用い領域提案もCNNで処理、高速化した物体検出モデル`},
{target:`FCN (Fully Convolutional Network)`, content:`全結合層を畳み込み層に置換し画像ごとのセグメンテーションを実現`},
{target:`FPN`, content:`マルチスケール特徴を統合し小物体も検出可能にしたネットワーク`},
{target:`GoogLeNet`, content:`Inceptionモジュールで計算効率を保ちながら深層化したCNN`},
{target:`Mask R-CNN`, content:`Faster R-CNNにセグメンテーションマスク出力を追加したモデル`},
{target:`MnasNet`, content:`モバイル端末向けにNASで最適化した効率的CNN`},
{target:`MobileNet`, content:`軽量化畳み込み(DWConv)で低リソース環境向けCNN`},
{target:`NAS (Neural Architecture Search)`, content:`自動でニューラルネット構造を探索する手法`},
{target:`OpenPose`, content:`人体の関節を検出し姿勢推定を行うCNNベースの手法`},
{target:`PSPNet`, content:`ピラミッドプーリングでマルチスケールのセマンティックセグメンテーション`},
{target:`ResNet`, content:`残差接続で非常に深いCNNでも学習可能にした構造`},
{target:`SegNet`, content:`エンコーダ・デコーダ型で効率的にセマンティックセグメンテーション`},
{target:`SENet`, content:`チャンネル間の重要度を学習し特徴表現を強化するCNN`},
{target:`SSD`, content:`1ステージで物体検出と分類を同時に行う高速モデル`},
{target:`U-Net`, content:`医療画像などで使われるエンコーダ・デコーダ型セグメンテーション`},
{target:`VGG`, content:`シンプルな3×3畳み込みを積み重ねた深層CNN`},
{target:`Vision Transformer`, content:`Transformerを画像に応用し全体注意で特徴抽出するモデル`},
{target:`Wide ResNet`, content:`ResNetの層幅を広げ精度向上と学習安定化を両立`},
{target:`YOLO`, content:`1ステージで物体の位置とクラスを同時予測する高速検出モデル`},
{target:`一般物体認識`, content:`画像内のカテゴリを識別するタスク`},
{target:`インスタンスセグメンテーション`, content:`各物体ごとにマスクを出力するセグメンテーション`},
{target:`姿勢推定`, content:`画像から人体や物体の関節・骨格位置を推定`},
{target:`セマンティックセグメンテーション`, content:`ピクセル単位でクラスを分類するタスク`},
{target:`物体検出`, content:`画像内の物体位置とクラスを検出するタスク`},
{target:`物体識別`, content:`検出された物体のカテゴリを識別するタスク`},
{target:`パノプティックセグメンテーション`, content:`セマンティック＋インスタンスセグメンテーションを統合したタスク`},
{target:`ーーーーー`, content:`27. 自然言語処理`},
{target:`BERT`, content:`双方向Transformerで文脈を理解し自然言語理解を強化したモデル`},
{target:`BoW (Bag-of-Words)`, content:`単語出現頻度をベクトル化し文書を表現する手法`},
{target:`CBOW`, content:`周囲の単語から中心単語を予測するword2vecの学習手法`},
{target:`CEC`, content:`言語モデルでエンコーディング中に情報圧縮する技術（Context Encoding Compression）`},
{target:`ChatGPT`, content:`GPT系列を基に会話生成に特化した大規模言語モデル`},
{target:`ELMo`, content:`文脈に応じて単語表現を動的に変化させる双方向RNN型埋め込み`},
{target:`fastText`, content:`単語の文字n-gramも考慮する効率的な単語埋め込み手法`},
{target:`GLUE`, content:`自然言語理解タスクの総合評価ベンチマーク`},
{target:`GPT-n`, content:`Transformerベースの自己回帰型大規模言語モデルのシリーズ`},
{target:`n-gram`, content:`連続n単語をまとめて特徴化するテキスト解析手法`},
{target:`PaLM`, content:`Googleの大規模言語モデル。高精度の自然言語理解・生成を実現`},
{target:`Seq2Seq`, content:`入力系列を別系列に変換するエンコーダ・デコーダ型モデル`},
{target:`TF-IDF`, content:`単語の文書内頻度と逆文書頻度から重要度を計算する手法`},
{target:`word2vec`, content:`単語を低次元ベクトルに変換し意味的関係を保持するモデル`},
{target:`感情分析`, content:`テキストからポジティブ・ネガティブなど感情を分類するタスク`},
{target:`機械翻訳`, content:`ある言語の文章を別言語に自動翻訳するタスク`},
{target:`形態素解析`, content:`文を単語・形態素に分割し品詞などを付与する処理`},
{target:`構文解析`, content:`文の文法構造を解析し構造木などで表現する処理`},
{target:`質問応答`, content:`質問に対して文書や知識ベースから適切な答えを返すタスク`},
{target:`情報検索`, content:`キーワードやクエリに基づき文書やデータを検索するタスク`},
{target:`スキップグラム`, content:`中心単語から周囲単語を予測するword2vecの学習手法`},
{target:`単語埋め込み`, content:`単語をベクトル化して意味情報を保持する表現手法`},
{target:`分散表現`, content:`単語や文書を連続値ベクトルで表し類似度計算可能にする手法`},
{target:`文書要約`, content:`長文から重要情報を抽出または生成し短くまとめるタスク`},
{target:`ワンホットベクトル`, content:`単語を0/1のベクトルで表現する基本的符号化手法`},
{target:`大規模言語モデル(LLM)`, content:`巨大データで学習したTransformerベースの生成・理解モデル`},
{target:`統計的機械翻訳`, content:`単語・フレーズ出現確率に基づき翻訳を行う古典的翻訳手法`},
{target:`ーーーーー`, content:`28. 音声処理`},
{target:`A-D変換`, content:`アナログ音声信号をデジタル値に変換する処理`},
{target:`WaveNet`, content:`音声波形を直接生成する深層学習ベースの音声合成モデル`},
{target:`音韻`, content:`言語の音声上の意味を区別する最小単位の音の体系`},
{target:`音声合成`, content:`テキストから人間の声に近い音声を生成する技術`},
{target:`音声認識`, content:`音声信号を文字列や意味情報に変換する技術`},
{target:`音素`, content:`言語で意味を区別する最小の音の単位`},
{target:`隠れマルコフモデル`, content:`音声など連続データの状態遷移を確率的に表すモデル`},
{target:`感情分析`, content:`音声の特徴から話者の感情状態を判定するタスク`},
{target:`高速フーリエ変換 (FFT)`, content:`音声波形を周波数成分に変換する効率的アルゴリズム`},
{target:`スペクトル包絡`, content:`音声スペクトルの滑らかな輪郭。声質特徴を表す`},
{target:`パルス符号変調器 (PCM)`, content:`音声を一定周期でサンプリングしデジタル化する方式`},
{target:`フォルマント`, content:`音声の共鳴周波数で母音などの特徴を表すピーク`},
{target:`フォルマント周波数`, content:`フォルマントの中心周波数で声質識別に重要`},
{target:`メル周波数ケプストラム係数 (MFCC)`, content:`メル尺度で音声を周波数特徴ベクトル化した指標`},
{target:`メル尺度`, content:`人間の聴覚特性に基づき周波数を非線形に変換した尺度`},
{target:`話者識別`, content:`音声から話者個人を認識・判別するタスク`},
{target:`CTC`, content:`時系列データで入力長と出力長が異なる場合に学習可能な損失関数`},
{target:`ーーーーー`, content:`29. 深層強化学習`},
{target:`A3C`, content:`複数エージェントを非同期で学習させるアクター・クリティック手法`},
{target:`Agent57`, content:`Atariゲームで人間超え性能を達成した強化学習エージェント`},
{target:`APE-X`, content:`DQNを分散化して大規模経験リプレイで学習効率を向上させた手法`},
{target:`DQN`, content:`Q学習を深層ネットワークで近似し高次元状態に対応した手法`},
{target:`OpenAI Five`, content:`Dota2で人間トッププレイヤーと対戦したマルチエージェントRL`},
{target:`PPO`, content:`安定した方策更新を実現するクリップ付き確率的アクター・クリティック`},
{target:`Rainbow`, content:`DQNに複数改善技術を統合した高性能強化学習モデル`},
{target:`RLHF`, content:`人間のフィードバックを報酬に変換して言語モデルを強化学習で調整`},
{target:`sim2real`, content:`シミュレーション学習を実環境に転移する技術`},
{target:`アルファスター (AlphaStar)`, content:`StarCraft IIでトップ人間プレイヤーを超えたマルチエージェントRL`},
{target:`オフライン強化学習`, content:`事前収集データのみで方策を学習する手法`},
{target:`残差強化学習`, content:`基本方策に残差を学習させ性能改善する手法`},
{target:`状態表現学習`, content:`高次元状態を効率的な潜在表現に圧縮する学習`},
{target:`ダブル DQN`, content:`Q値過大評価を防ぐ改良DQN。2つのネットワークで更新`},
{target:`デュエリングネットワーク`, content:`価値関数とアクション優位性関数を分離してQ値を推定`},
{target:`ドメインランダマイゼーション`, content:`環境差異に対して方策が汎化するよう学習環境をランダム化`},
{target:`ノイジーネットワーク`, content:`方策の探索を促進するためにネットワークにノイズを加える手法`},
{target:`報酬成形`, content:`タスク達成を促す追加報酬を設計して学習を加速する手法`},
{target:`マルチエージェント強化学習 (MARL)`, content:`複数エージェントが同環境で協調・競合して学習するRL`},
{target:`連続値制御`, content:`行動が連続値を取る環境での制御問題を扱うRL`},
{target:`ーーーーー`, content:`30. データ生成`},
{target:`CycleGAN`, content:`ラベルなし画像間の変換を学習するCycle制約付きGAN`},
{target:`DCGAN`, content:`畳み込み層を使った安定性向上型の敵対的生成ネットワーク`},
{target:`Diffusion Model`, content:`ノイズ付加と逆拡散で高品質画像を生成するモデル`},
{target:`NeRF`, content:`3Dシーンの体積レンダリングをニューラルネットで生成する手法`},
{target:`Pix2Pix`, content:`条件付きGANで入力画像から対応画像を生成するモデル`},
{target:`音声生成`, content:`テキストや潜在変数から自然な音声波形を生成する技術`},
{target:`画像生成`, content:`ランダムノイズや条件入力から画像を生成する技術`},
{target:`敵対的生成ネットワーク (GAN)`, content:`生成器と識別器を競わせてリアルなデータを生成する手法`},
{target:`文章生成`, content:`文脈や条件に応じて自然な文章を自動生成する技術`},
{target:`ーーーーー`, content:`31. 転移学習・ファインチューニング`},
{target:`Few-shot`, content:`少数の例からタスクを学習・適応する手法`},
{target:`One-shot`, content:`1つの例だけで新しいタスクを学習する手法`},
{target:`自己教師あり学習`, content:`ラベルなしデータから擬似ラベルを生成し学習する手法`},
{target:`事前学習`, content:`大規模データで基礎モデルを学習し下流タスクに活用`},
{target:`事前学習済みモデル`, content:`事前学習が完了したモデル。転移学習や微調整に利用`},
{target:`破壊的忘却`, content:`新しいタスク学習で既存知識が失われる現象`},
{target:`半教師あり学習`, content:`一部ラベル付きデータと大量ラベルなしデータで学習する手法`},
{target:`ーーーーー`, content:`32. マルチモーダル`},
{target:`CLIP`, content:`画像とテキストを同一ベクトル空間で表現し関連性を評価するモデル`},
{target:`DALL-E`, content:`テキストから高品質画像を生成する大規模生成モデル`},
{target:`Flamingo`, content:`テキスト・画像を統合し少数例で推論可能なマルチモーダルモデル`},
{target:`Image Captioning`, content:`画像の内容を自動で文章化するタスク`},
{target:`Text-To-Image`, content:`テキスト記述を基に画像を生成するタスク`},
{target:`Visual Question Answering`, content:`画像と質問から適切な答えを生成するタスク`},
{target:`Unified-IO`, content:`複数モーダル・複数タスクを統合的に扱う大規模基盤モデル`},
{target:`Zero-shot`, content:`学習していないタスクにも事前知識で対応可能な学習方式`},
{target:`基盤モデル`, content:`大規模データで学習され多用途に応用可能な汎用モデル`},
{target:`マルチタスク学習`, content:`複数タスクを同時に学習して性能向上と汎化を図る手法`},
{target:`ーーーーー`, content:`33. モデルの解釈性`},
{target:`CAM`, content:`畳み込み特徴マップを利用して画像分類の注目領域を可視化`},
{target:`Grad-CAM`, content:`勾配情報を使い重要領域を強調するCAMの拡張手法`},
{target:`LIME`, content:`モデルの局所的予測に対する解釈可能性を提供する手法`},
{target:`Permutation Importance`, content:`特徴をシャッフルし性能低下で重要度を評価する手法`},
{target:`SHAP`, content:`各特徴の予測への寄与を理論的に分配して可視化する手法`},
{target:`説明可能AI (XAI)`, content:`モデルの予測根拠や挙動を人間が理解可能にする技術`},
{target:`ーーーーー`, content:`34. モデルの軽量化`},
{target:`蒸留`, content:`大モデルの知識を小モデルに移し軽量化・高速化する手法`},
{target:`宝くじ仮説`, content:`大モデルの小さなサブネットワークが高性能を示す理論`},
{target:`プルーニング`, content:`不要な重みやニューロンを削除しモデルを圧縮する手法`},
{target:`モデル圧縮`, content:`精度を維持しつつモデルサイズや計算量を削減する技術`},
{target:`量子化`, content:`重みや入力を低ビット化し推論計算を高速・省メモリ化する手法`},
{target:`ーーーーー`, content:`35. AI プロジェクトの進め方`},
{target:`AI のビジネス活用`, content:`AIを業務改善・新規サービス創出・意思決定支援に応用する取り組み`},
{target:`AI プロジェクトの進め方`, content:`データ収集・モデル開発・評価・運用までの体系的なAI導入プロセス`},
{target:`BPR`, content:`業務プロセスを抜本的に見直し効率化・価値向上を図る手法`},
{target:`CRISP-DM`, content:`データ分析プロジェクトの標準プロセス（理解→準備→モデリング→評価→展開）`},
{target:`CRISP-ML`, content:`CRISP-DMを機械学習プロジェクト向けに拡張したプロセスモデル`},
{target:`Docker`, content:`アプリやモデルをコンテナ化し環境依存を排除する仮想化技術`},
{target:`Jupyter Notebook`, content:`コード・説明・可視化を統合して実験・共有できる開発環境`},
{target:`MLOps`, content:`モデル開発・デプロイ・運用を統合し再現性と効率を高める運用手法`},
{target:`PoC`, content:`技術やモデルの実現可能性を小規模で検証する実証実験`},
{target:`Python`, content:`機械学習・AI開発で広く使われる高水準プログラミング言語`},
{target:`Web API`, content:`アプリケーション間で機能やデータを提供・連携するインターフェース`},
{target:`アジャイル`, content:`小さく反復的に開発し顧客価値を早期に提供する開発手法`},
{target:`ウォーターフォール`, content:`要件定義→設計→実装→テスト→運用の順に進める従来型開発手法`},
{target:`オープン・イノベーション`, content:`外部知識や技術を積極的に取り入れ自社価値を創出する戦略`},
{target:`クラウド`, content:`インターネット経由で計算資源・ストレージ・サービスを提供する環境`},
{target:`産学連携`, content:`大学や研究機関と企業が協働し研究・開発・人材育成を行う取り組み`},
{target:`ステークホルダーのニーズ`, content:`利害関係者の要求や期待を理解しプロジェクト設計に反映すること`},
{target:`データサイエンティスト`, content:`データ分析・モデル構築・意思決定支援を行う専門職`},
{target:`他企業や他業種との連携`, content:`異なる企業や業界と協業し技術・知見を共有して新価値を創出`},
{target:`ーーーーー`, content:`36. データの収集・加工・分析・学習`},
{target:`アノテーション`, content:`データにラベルや情報を付与して学習可能にする作業`},
{target:`オープンデータセット`, content:`誰でも利用可能な公開済み学習・評価用データ`},
{target:`コーパス`, content:`言語研究やNLPで利用される体系的に収集された文書集`},
{target:`データリーケージ`, content:`学習データにテスト情報が含まれ性能を過大評価する現象`},
{target:`ーーーーー`, content:`37. AI に必要な数理・統計知識`},
{target:`移動平均`, content:`時系列データの変動を平滑化する平均計算手法`},
{target:`確率分布`, content:`確率変数が取り得る値とその確率の関係を示す関数`},
{target:`確率変数`, content:`取り得る値が確率によって決まる変数`},
{target:`確率密度`, content:`連続確率変数がある値を取る相対的な可能性の密度`},
{target:`疑似相関`, content:`第三の変数の影響で見かけ上生じた相関`},
{target:`期待値`, content:`確率変数の平均値。確率加重平均で算出`},
{target:`帰無仮説`, content:`統計検定で差や関係がないと仮定する基準仮説`},
{target:`共分散`, content:`2変数の同時変動の程度を示す指標`},
{target:`コサイン類似度`, content:`ベクトル間の角度で類似度を測る指標`},
{target:`最小二乗法`, content:`誤差平方和を最小化してモデル係数を推定する手法`},
{target:`最頻値`, content:`データ集合で最も頻繁に出現する値`},
{target:`最尤法`, content:`観測データが最も生じやすいようにパラメータを推定する手法`},
{target:`条件付き確率`, content:`ある事象が起きた場合の別の事象の確率`},
{target:`正規分布`, content:`平均値周辺に集中するベル型の連続確率分布`},
{target:`相関係数`, content:`2変数間の線形関係の強さと方向を示す指標`},
{target:`相互情報量`, content:`2変数の情報量共有の程度を示す指標`},
{target:`対立仮説`, content:`帰無仮説に対し差や関係があるとする仮説`},
{target:`中央値`, content:`データを昇順に並べたとき中央に位置する値`},
{target:`度数分布`, content:`データの値ごとの出現頻度を整理した表`},
{target:`二項分布`, content:`成功/失敗の2値試行の回数分布を表す確率分布`},
{target:`外れ値`, content:`他のデータから大きく逸脱した値`},
{target:`標準偏差`, content:`データの散らばり（分散の平方根）を示す指標`},
{target:`平均`, content:`データの合計をデータ数で割った値`},
{target:`分散`, content:`データの散らばりの度合い（偏差平方平均）`},
{target:`偏相関係数`, content:`他の変数の影響を除いた2変数間の相関`},
{target:`ベルヌーイ分布`, content:`成功/失敗の二値事象の確率分布`},
{target:`ポアソン分布`, content:`単位時間・単位空間あたりの事象発生回数の分布`},
{target:`マハラノビス距離`, content:`データ分布の共分散を考慮した多次元距離`},
{target:`ユークリッド距離`, content:`直線距離に基づく最も基本的な2点間距離`},
{target:`ーーーーー`, content:`1. 個人情報保護法`},
{target:`個人情報`, content:`氏名や住所等、個人を識別できる情報`},
{target:`個人データ`, content:`データベース化された個人情報`},
{target:`保有個人データ`, content:`事業者が保有し開示請求対象となる個人情報`},
{target:`要配慮個人情報`, content:`健康・思想など差別につながる情報`},
{target:`匿名加工情報`, content:`特定個人を識別できない形に加工した情報`},
{target:`仮名加工情報`, content:`仮名化し再識別を抑制した情報`},
{target:`個人識別符号`, content:`指紋・顔など本人識別できる符号`},
{target:`GDPR`, content:`EU一般データ保護規則。厳格な国際規範`},
{target:`利用目的`, content:`収集時に明示される利用範囲`},
{target:`第三者提供`, content:`本人同意なく外部へ渡す行為。制限あり`},
{target:`委託`, content:`業務やプロジェクトを外部企業・専門家に任せること`},
{target:`ーーーーー`, content:`2. 著作権法`},
{target:`創作性`, content:`独自性ある表現に認められる要件`},
{target:`著作物`, content:`思想や感情を表現した成果物`},
{target:`AI生成物`, content:`AIが出力した成果物の著作権は議論中`},
{target:`著作権侵害`, content:`無断利用で権利者の利益を害する行為`},
{target:`利用規約`, content:`データ利用条件を規定する文書`},
{target:`ライセンス契約`, content:`ソフトやデータの使用条件を定める契約`},
{target:`著作権法30条4`, content:`機械学習での利用を認める特例規定`},
{target:`ーーーーー`, content:`3. 特許法`},
{target:`発明`, content:`自然法則を利用した技術的思想の創作`},
{target:`新規性`, content:`公知でないこと。特許要件の一つ`},
{target:`進歩性`, content:`既存技術から容易に想到できないこと`},
{target:`職務発明`, content:`従業員が職務上生み出した発明`},
{target:`特許権`, content:`発明を一定期間独占できる権利`},
{target:`知的財産権`, content:`特許・著作権等の無体財産権全般`},
{target:`ーーーーー`, content:`4. 不正競争防止法`},
{target:`営業秘密`, content:`秘密管理・有用性・非公知の3要件を満たす情報`},
{target:`限定提供データ`, content:`特定範囲に提供し不正取得を禁止されるデータ`},
{target:`ーーーーー`, content:`5. 独占禁止法`},
{target:`競争制限`, content:`市場支配や談合など競争を妨げる行為`},
{target:`公正競争阻害性`, content:`AIによる価格操作等で懸念される効果`},
{target:`ーーーーー`, content:`6. AI開発委託契約`},
{target:`請負契約`, content:`完成物引渡しを目的とする契約`},
{target:`準委任契約`, content:`作業遂行自体を目的とする契約`},
{target:`精度保証`, content:`成果物の性能保証条項。注意が必要`},
{target:`保守契約`, content:`運用後の修正や改善を担保する契約`},
{target:`NDA`, content:`秘密保持契約。委託時の前提条件`},
{target:`AI・データ利用契約ガイドライン`, content:`経産省が策定した契約指針`},
{target:`PoC`, content:`技術やモデルの実現可能性を小規模で検証する実証実験`},
{target:`ーーーーー`, content:`7. AIサービス提供契約`},
{target:`SaaS`, content:`クラウド経由で提供されるサービス形態`},
{target:`データ利用権`, content:`サービス提供者がデータを利用する権利`},
{target:`利用規約`, content:`利用者と提供者間の条件を定める`},
{target:`精度保証`, content:`サービス精度に関する保証条項`},
{target:`ーーーーー`, content:`8. 国内外のガイドライン`},
{target:`AI倫理`, content:`公平性・透明性・安全性を守る規範`},
{target:`AIガバナンス`, content:`倫理・法律遵守を確保する仕組み`},
{target:`価値原則`, content:`人権・公正・説明責任等の原則`},
{target:`ハードロー`, content:`法律による強制力ある規範。`},
{target:`ソフトロー`, content:`ガイドライン等の非拘束的規範。`},
{target:`リスクベースアプローチ`, content:`リスクに応じ規制強度を調整する枠組み`},
{target:`ーーーーー`, content:`9. プライバシー`},
{target:`プライバシー・バイ・デザイン`, content:`設計段階から保護を組込む考え方`},
{target:`カメラ画像利活用ガイドブック`, content:`防犯カメラ等利用時の指針`},
{target:`ーーーーー`, content:`10. 公平性`},
{target:`アルゴリズムバイアス`, content:`学習データ偏りが差別を助長する現象`},
{target:`サンプリングバイアス`, content:`標本抽出の偏りで結果が歪む現象`},
{target:`センシティブ属性`, content:`性別・人種など差別に関わる属性`},
{target:`代理変数`, content:`本来利用不可情報を間接的に表す変数`},
{target:`公平性の定義`, content:`AIや意思決定システムで差別や偏りがない状態の基準`},
{target:`データの偏り`, content:`学習データが特定属性や分布に偏っている状態`},
{target:`ーーーーー`, content:`11. 安全性とセキュリティ`},
{target:`アドバーサリアル攻撃`, content:`微小摂動で誤認識させる攻撃`},
{target:`データ汚染`, content:`学習データを改ざんし性能を低下させる攻撃`},
{target:`データ窃取`, content:`訓練データを盗み出す攻撃`},
{target:`モデル窃取`, content:`ブラックボックスから同等モデルを再現する攻撃`},
{target:`モデル汚染`, content:`悪意あるデータでモデル性能を破壊`},
{target:`セキュリティ・バイ・デザイン`, content:`設計段階から安全性を確保する考え方`},
{target:`ーーーーー`, content:`12. 悪用`},
{target:`ディープフェイク`, content:`本物そっくりの偽映像を生成する技術`},
{target:`フェイクニュース`, content:`虚偽情報を拡散し世論を操作する行為`},
{target:`ーーーーー`, content:`13. 透明性`},
{target:`説明可能性`, content:`判断根拠を人間が理解できること`},
{target:`ブラックボックス`, content:`内部処理が理解困難なモデル`},
{target:`データの来歴`, content:`データ収集・加工の履歴を明示する情報`},
{target:`ーーーーー`, content:`14. 民主主義`},
{target:`エコーチェンバー`, content:`同質意見のみが強化される環境。`},
{target:`フィルターバブル`, content:`個人化推薦で情報が偏る現象`},
{target:`フェイクニュース`, content:`世論操作や分断を招く偽情報`},
{target:`ーーーーー`, content:`15. 環境保護`},
{target:`気候変動`, content:`AI活用で緩和策・適応策の研究`},
{target:`モデル学習の電力消費`, content:`大規模DL学習で環境負荷増加が課題`},
{target:`ーーーーー`, content:`16. 労働政策`},
{target:`AIとの協働`, content:`人とAIが補完し合う働き方`},
{target:`スキルの喪失`, content:`自動化により人間技能が失われる懸念`},
{target:`労働力不足`, content:`AI導入で補完される社会課題`},
{target:`ーーーーー`, content:`17. その他の重要な価値`},
{target:`インクルージョン`, content:`多様な人々を排除しない設計思想`},
{target:`軍事利用`, content:`AI兵器化の是非を巡る倫理問題`},
{target:`死者への敬意`, content:`故人のデータ利用に伴う倫理問題`},
{target:`人間の自律性`, content:`判断や意思決定をAIに委ねすぎない原則`},
{target:`ーーーーー`, content:`18. AIガバナンス`},
{target:`倫理アセスメント`, content:`倫理的影響を事前評価する仕組み`},
{target:`AIポリシー`, content:`組織内AI利用の基本方針。`},
{target:`ダイバーシティ`, content:`多様性確保によりバイアスを抑制`},
{target:`AI監査`, content:`モデルや運用を第三者が検証`},
{target:`人間の関与`, content:`AI判断に人が責任を持ち関与する仕組み`},
{target:`モニタリング`, content:`運用中モデルを継続監視`},
{target:`再現性`, content:`結果を繰返し再現できる信頼性`},
{target:`トレーサビリティ`, content:`データや処理過程を追跡可能にする仕組み`},
]
